# Generalizing from a Few Examples: A Survey on Few-Shot Learning
* **Author**: YAQING WANG、QUANMING YAO、JAMES T. KWOK、LIONEL M. NI
* **Abstract**: Artificial intelligence succeeds in data-intensive applications, but it lacks the ability of learning from a limited number of examples. To tackle this problem, Few-Shot Learning (FSL) is proposed. It can rapidly generalize from new tasks of limited supervised experience using prior knowledge. To fully understand FSL, we conduct a survey study. We first clarify a formal definition for FSL. Then we figure out that the unreliable empirical risk  minimizer is the core issue of FSL. Based on how prior knowledge is used to deal with the core issue, we categorize different FSL methods into three perspectives: data uses the prior knowledge to augment the supervised experience, model constrains the hypothesis space by prior knowledge, and algorithm uses prior knowledge to alter the search for the parameter of the best hypothesis in the hypothesis space. Under this unified taxonomy, we provide thorough discussion of pros and cons across different categories. Finally, we propose possible directions for FSL in terms of problem setup, techniques, applications and theories, in hope of providing insights to following research.
* **Summary**: Few-Shot Learning (FSL) targets at bridging this gap between AI and human-like learning. It can learn new tasks of limited supervised information by incorporating prior knowledge. FSL acts as a test-bed for AI, helps to relieve the burden of collecting large-scale supervised date for
  industrial usages, or makes the learning of rare cases possible. With both academic dream of AI and industrial needs for cheap learning, FSL draws much attention and becomes a hot topic. In this survey, we provide a comprehensive and systematic review of FSL. We first formally define FSL, and discuss the relatedness and difference of FSL with respect to relevant learning problems such as semi-supervised learning, imbalanced learning,  transfer learning and meta-learning. Then, we point out the core issue of FSL based on error decomposition in machine learning. We figure out that it is the unreliable empirical risk minimizer that makes FSL hard to learn. This can be relieved by satisfying or reducing the sample complexity of  learning. Understanding the core issue can help categorize different works into data, model and algorithm according to how they solve the core
  issue using prior knowledge: data augments the supervised experience of FSL, model constrain the hypothesis space of FSL, and algorithm alters the search strategy for the parameter of the best hypothesis in hypothesis space to solve FSL. Within each category, the pros and cons of different categories are thoroughly discussed and some summary of the insights under each category is presented. For future works, we provide possible directions including problem setup, techniques, applications and theories to explore, in hope of inspiring future research in FSL.
* **Keywords**: Few-shot learning, One-shot learning, Low-shot learning, Small sample learning, Meta-learning, Prior knowledge
* **个人想法**：非常不错的小样本学习综述论文，从Data、Model、Algorithm三个方面介绍了现有的小样本学习领域内的方法。以数学的形式具体解释了小样本学习中的困难点，看完非常有启发性。总之，如果想要了解小样本学习看这篇就够了。

